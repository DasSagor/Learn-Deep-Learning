{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11ed9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a69c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a206397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7aa7594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de4b23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d87be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e905b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mnsc = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = mnsc.fit_transform(x_train)\n",
    "x_test_scaled = mnsc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a965ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7b8d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "# model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ea0294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f72bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "566ef98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.3454 - val_loss: 1.3148\n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1939 - val_loss: 1.1666\n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0628 - val_loss: 1.0265\n",
      "Epoch 4/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9324 - val_loss: 0.8980\n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8109 - val_loss: 0.7772\n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6998 - val_loss: 0.6693\n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6007 - val_loss: 0.5802\n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5158 - val_loss: 0.5017\n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4406 - val_loss: 0.4310\n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3749 - val_loss: 0.3664\n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3174 - val_loss: 0.3093\n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2666 - val_loss: 0.2601\n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2234 - val_loss: 0.2178\n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1868 - val_loss: 0.1813\n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1553 - val_loss: 0.1504\n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1283 - val_loss: 0.1249\n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1066 - val_loss: 0.1036\n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0885 - val_loss: 0.0863\n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0739 - val_loss: 0.0722\n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0619 - val_loss: 0.0611\n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0526 - val_loss: 0.0525\n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0454 - val_loss: 0.0456\n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0397 - val_loss: 0.0404\n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0353 - val_loss: 0.0365\n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0321 - val_loss: 0.0335\n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0296 - val_loss: 0.0313\n",
      "Epoch 27/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0278 - val_loss: 0.0296\n",
      "Epoch 28/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0263 - val_loss: 0.0284\n",
      "Epoch 29/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0253 - val_loss: 0.0275\n",
      "Epoch 30/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0245 - val_loss: 0.0268\n",
      "Epoch 31/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0239 - val_loss: 0.0262\n",
      "Epoch 32/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0235 - val_loss: 0.0258\n",
      "Epoch 33/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0231 - val_loss: 0.0255\n",
      "Epoch 34/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0252\n",
      "Epoch 35/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.0249\n",
      "Epoch 36/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 37/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0220 - val_loss: 0.0244\n",
      "Epoch 38/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0216 - val_loss: 0.0240\n",
      "Epoch 40/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0214 - val_loss: 0.0238\n",
      "Epoch 41/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 42/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0209 - val_loss: 0.0233\n",
      "Epoch 43/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0207 - val_loss: 0.0231\n",
      "Epoch 44/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0205 - val_loss: 0.0229\n",
      "Epoch 45/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.0226\n",
      "Epoch 46/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0201 - val_loss: 0.0224\n",
      "Epoch 47/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0199 - val_loss: 0.0222\n",
      "Epoch 48/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.0218\n",
      "Epoch 50/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0193 - val_loss: 0.0215\n",
      "Epoch 51/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 52/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0189 - val_loss: 0.0211\n",
      "Epoch 53/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - val_loss: 0.0209\n",
      "Epoch 54/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0185 - val_loss: 0.0207\n",
      "Epoch 55/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 56/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 57/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 58/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.0199\n",
      "Epoch 59/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0175 - val_loss: 0.0197\n",
      "Epoch 60/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0173 - val_loss: 0.0195\n",
      "Epoch 61/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0171 - val_loss: 0.0193\n",
      "Epoch 62/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.0191\n",
      "Epoch 63/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0167 - val_loss: 0.0189\n",
      "Epoch 64/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0166 - val_loss: 0.0187\n",
      "Epoch 65/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 66/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 67/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 68/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0180\n",
      "Epoch 69/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0156 - val_loss: 0.0178\n",
      "Epoch 70/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.0176\n",
      "Epoch 71/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0152 - val_loss: 0.0174\n",
      "Epoch 72/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0151 - val_loss: 0.0172\n",
      "Epoch 73/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 74/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0147 - val_loss: 0.0169\n",
      "Epoch 75/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 76/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - val_loss: 0.0166\n",
      "Epoch 77/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 78/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.0163\n",
      "Epoch 79/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 80/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 81/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.0158\n",
      "Epoch 82/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 83/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0155\n",
      "Epoch 84/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 85/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 86/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 87/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 88/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 89/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 90/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 91/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 92/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 93/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 94/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 95/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 96/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 97/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 98/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 99/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 100/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 101/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 102/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 103/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 104/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 105/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 106/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 107/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 108/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 109/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 110/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 111/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 112/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 113/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 114/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 115/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 116/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 117/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 118/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 119/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 120/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 121/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 122/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 123/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 124/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 125/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 126/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 127/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 128/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 129/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 130/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 131/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 132/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 133/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 134/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 135/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 136/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 137/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 138/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 139/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 140/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 141/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 142/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 143/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 144/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 145/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 146/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 147/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 148/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 149/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 150/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 151/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 152/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 153/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 154/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 155/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 156/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 157/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 158/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 159/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 160/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 161/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 162/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 163/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 164/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 165/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 166/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 167/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 168/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 169/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 170/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 171/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 172/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 173/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 174/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 175/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 176/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 177/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 178/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 184/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 185/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 186/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 187/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 188/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 189/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 190/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 191/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 192/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 193/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 194/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 195/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 196/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 197/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 198/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 199/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 200/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled,y_train,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73970757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f23c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296671723465586"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1589697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2405f433020>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
